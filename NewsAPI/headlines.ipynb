{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Jim Cramer advises investors to sell these groups of stocks 'whenever they bounce'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Hospitals Made Use of Modified Tesla-Donated Breathing Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Your boss said 'You're furloughed.' What does that mean exactly?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>These stocks millennials are investing in are 'very good for speculation ' Jim Cramer says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Bank of America downgrades Tesla citing too high valuation after stock's recent massive run</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla considers building its next factory in Austin or Tulsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>DOJ and state AGs likely to bring antitrust suits against Google: Report</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Final Trades: BABA SLX &amp; PENN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Assessing the stock market after one of the fastest declines and subsequent comebacks in history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Health officials issue dire warnings; FBI scrutinizes senators' stock sales: This week's recap and best reads</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     source  \\\n",
       "0    2020-04-16  CNBC        \n",
       "1    2020-04-17  Bloomberg   \n",
       "2    2020-04-17  CNBC        \n",
       "3    2020-04-21  CNBC        \n",
       "4    2020-04-22  CNBC        \n",
       "..          ...   ...        \n",
       "148  2020-05-15  CNBC        \n",
       "149  2020-05-15  CNBC        \n",
       "150  2020-05-15  CNBC        \n",
       "151  2020-05-16  CNBC        \n",
       "152  2020-05-16  CNBC        \n",
       "\n",
       "                                                                                                          headline  \n",
       "0    Jim Cramer advises investors to sell these groups of stocks 'whenever they bounce'                             \n",
       "1    Hospitals Made Use of Modified Tesla-Donated Breathing Machines                                                \n",
       "2    Your boss said 'You're furloughed.' What does that mean exactly?                                               \n",
       "3    These stocks millennials are investing in are 'very good for speculation ' Jim Cramer says                     \n",
       "4    Bank of America downgrades Tesla citing too high valuation after stock's recent massive run                    \n",
       "..                                                                                           ...                    \n",
       "148  Tesla considers building its next factory in Austin or Tulsa                                                   \n",
       "149  DOJ and state AGs likely to bring antitrust suits against Google: Report                                       \n",
       "150  Final Trades: BABA SLX & PENN                                                                                  \n",
       "151  Assessing the stock market after one of the fastest declines and subsequent comebacks in history               \n",
       "152  Health officials issue dire warnings; FBI scrutinizes senators' stock sales: This week's recap and best reads  \n",
       "\n",
       "[153 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load headlines2.csv\n",
    "path2 = os.path.join(os.path.abspath('headlines2.csv'))\n",
    "df_headlines = pd.read_csv(path2)\n",
    "df_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Jim Cramer advises investors to sell these groups of stocks 'whenever they bounce'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Hospitals Made Use of Modified Tesla-Donated Breathing Machines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Your boss said 'You're furloughed.' What does that mean exactly?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>These stocks millennials are investing in are 'very good for speculation ' Jim Cramer says</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Bank of America downgrades Tesla citing too high valuation after stock's recent massive run</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla considers building its next factory in Austin or Tulsa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>DOJ and state AGs likely to bring antitrust suits against Google: Report</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Final Trades: BABA SLX &amp; PENN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Assessing the stock market after one of the fastest declines and subsequent comebacks in history</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Health officials issue dire warnings; FBI scrutinizes senators' stock sales: This week's recap and best reads</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     source  \\\n",
       "0    2020-04-16  CNBC        \n",
       "1    2020-04-17  Bloomberg   \n",
       "2    2020-04-17  CNBC        \n",
       "3    2020-04-21  CNBC        \n",
       "4    2020-04-22  CNBC        \n",
       "..          ...   ...        \n",
       "148  2020-05-15  CNBC        \n",
       "149  2020-05-15  CNBC        \n",
       "150  2020-05-15  CNBC        \n",
       "151  2020-05-16  CNBC        \n",
       "152  2020-05-16  CNBC        \n",
       "\n",
       "                                                                                                          headline  \\\n",
       "0    Jim Cramer advises investors to sell these groups of stocks 'whenever they bounce'                              \n",
       "1    Hospitals Made Use of Modified Tesla-Donated Breathing Machines                                                 \n",
       "2    Your boss said 'You're furloughed.' What does that mean exactly?                                                \n",
       "3    These stocks millennials are investing in are 'very good for speculation ' Jim Cramer says                      \n",
       "4    Bank of America downgrades Tesla citing too high valuation after stock's recent massive run                     \n",
       "..                                                                                           ...                     \n",
       "148  Tesla considers building its next factory in Austin or Tulsa                                                    \n",
       "149  DOJ and state AGs likely to bring antitrust suits against Google: Report                                        \n",
       "150  Final Trades: BABA SLX & PENN                                                                                   \n",
       "151  Assessing the stock market after one of the fastest declines and subsequent comebacks in history                \n",
       "152  Health officials issue dire warnings; FBI scrutinizes senators' stock sales: This week's recap and best reads   \n",
       "\n",
       "     score  \n",
       "0   NaN     \n",
       "1   NaN     \n",
       "2   NaN     \n",
       "3   NaN     \n",
       "4   NaN     \n",
       "..   ..     \n",
       "148 NaN     \n",
       "149 NaN     \n",
       "150 NaN     \n",
       "151 NaN     \n",
       "152 NaN     \n",
       "\n",
       "[153 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty column to store sentiment scores per article\n",
    "df_headlines['score'] = np.nan\n",
    "df_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/asamra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jim', 'Cramer', 'advises', 'investors', 'to', 'sell', 'these', 'groups', 'of', 'stocks', \"'whenever\", 'they', 'bounce', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize essentially splits a sentence into words\n",
    "headline_0 = word_tokenize(df_headlines['headline'][0])\n",
    "print(headline_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/asamra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# Stop words are words that provide no sentiment meaning\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append ':' to stop_words list\n",
    "stop_words.append(':')\n",
    "#print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jim', 'Cramer', 'advises', 'investors', 'sell', 'groups', 'stocks', \"'whenever\", 'bounce', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "# Remove stop words from headline at index 0\n",
    "filtered_headline_0 = []\n",
    "for word in headline_0:\n",
    "    if word not in stop_words:\n",
    "        filtered_headline_0.append(word)\n",
    "print(filtered_headline_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/asamra/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists for each type of word: positive, negative and neurtral\n",
    "headline_0_pos = []\n",
    "headline_0_neg = []\n",
    "headline_0_neu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in algorithm determines sentiment of word\n",
    "# https://stackoverflow.com/questions/43646877/python-extract-positive-words-from-a-string-using-sentiment-vader/43647056\n",
    "for word in filtered_headline_0:\n",
    "    if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "        headline_0_pos.append(word)\n",
    "    elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "        headline_0_neg.append(word)\n",
    "    else:\n",
    "        headline_0_neu.append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(headline_0_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(headline_0_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jim', 'Cramer', 'advises', 'investors', 'sell', 'groups', 'stocks', \"'whenever\", 'bounce', \"'\"]\n"
     ]
    }
   ],
   "source": [
    "print(headline_0_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a formula to determine how to assign an article \n",
    "#score_0 = ((1/3)*len(headline_0_pos) - (1/3)*len(headline_0_neg))/len(filtered_headline_0)\n",
    "\"\"\"if len(headline_0_neu) >= len(headline_0_pos) and len(headline_0_neu) >= len(headline_0_neg):\n",
    "    score_0 = 0\n",
    "elif len(headline_0_pos) > len(headline_0_neg):\n",
    "    score_0 = 1\n",
    "else:\n",
    "    score_0 = -1\"\"\"\n",
    "\n",
    "score_0 = round((1*len(headline_0_pos) - 1*len(headline_0_neg) + 0*len(headline_0_neu))/len(filtered_headline_0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(score_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below, we perform the operations above for every row in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2020-04-16 0.0\n",
      "1 2020-04-17 0.0\n",
      "2 2020-04-17 0.0\n",
      "3 2020-04-21 0.0\n",
      "4 2020-04-22 0.0\n",
      "5 2020-04-22 0.0\n",
      "6 2020-04-22 -0.09\n",
      "7 2020-04-22 0.0\n",
      "8 2020-04-22 0.0\n",
      "9 2020-04-22 -0.08\n",
      "10 2020-04-23 0.0\n",
      "11 2020-04-24 0.0\n",
      "12 2020-04-24 0.0\n",
      "13 2020-04-24 0.0\n",
      "14 2020-04-25 0.0\n",
      "15 2020-04-25 0.0\n",
      "16 2020-04-25 0.0\n",
      "17 2020-04-26 0.0\n",
      "18 2020-04-27 0.0\n",
      "19 2020-04-27 0.0\n",
      "20 2020-04-27 0.0\n",
      "21 2020-04-27 0.0\n",
      "22 2020-04-27 0.0\n",
      "23 2020-04-27 0.0\n",
      "24 2020-04-27 0.0\n",
      "25 2020-04-28 0.0\n",
      "26 2020-04-28 0.0\n",
      "27 2020-04-28 0.0\n",
      "28 2020-04-28 0.0\n",
      "29 2020-04-28 0.0\n",
      "30 2020-04-28 0.0\n",
      "31 2020-04-28 0.0\n",
      "32 2020-04-28 0.0\n",
      "33 2020-04-28 0.0\n",
      "34 2020-04-29 0.0\n",
      "35 2020-04-29 0.0\n",
      "36 2020-04-29 0.0\n",
      "37 2020-04-29 0.0\n",
      "38 2020-04-29 -0.09\n",
      "39 2020-04-29 0.0\n",
      "40 2020-04-29 0.08\n",
      "41 2020-04-29 0.0\n",
      "42 2020-04-29 0.0\n",
      "43 2020-04-29 0.0\n",
      "44 2020-04-30 0.0\n",
      "45 2020-04-30 0.0\n",
      "46 2020-04-30 0.0\n",
      "47 2020-04-30 0.0\n",
      "48 2020-04-30 0.0\n",
      "49 2020-04-30 0.0\n",
      "50 2020-04-30 0.0\n",
      "51 2020-04-30 -0.08\n",
      "52 2020-04-30 0.0\n",
      "53 2020-04-30 -0.08\n",
      "54 2020-04-30 0.0\n",
      "55 2020-05-01 0.0\n",
      "56 2020-05-01 -0.11\n",
      "57 2020-05-01 0.0\n",
      "58 2020-05-01 0.0\n",
      "59 2020-05-01 0.0\n",
      "60 2020-05-01 0.0\n",
      "61 2020-05-01 0.0\n",
      "62 2020-05-01 0.0\n",
      "63 2020-05-02 0.0\n",
      "64 2020-05-02 0.0\n",
      "65 2020-05-02 0.0\n",
      "66 2020-05-02 0.0\n",
      "67 2020-05-04 0.0\n",
      "68 2020-05-04 0.0\n",
      "69 2020-05-04 0.0\n",
      "70 2020-05-04 0.0\n",
      "71 2020-05-04 0.0\n",
      "72 2020-05-05 0.08\n",
      "73 2020-05-05 0.0\n",
      "74 2020-05-05 0.0\n",
      "75 2020-05-06 0.0\n",
      "76 2020-05-07 0.0\n",
      "77 2020-05-07 0.0\n",
      "78 2020-05-07 0.0\n",
      "79 2020-05-07 0.0\n",
      "80 2020-05-07 0.0\n",
      "81 2020-05-07 0.0\n",
      "82 2020-05-07 0.0\n",
      "83 2020-05-08 0.0\n",
      "84 2020-05-08 0.0\n",
      "85 2020-05-08 0.0\n",
      "86 2020-05-08 0.0\n",
      "87 2020-05-08 0.0\n",
      "88 2020-05-08 0.0\n",
      "89 2020-05-08 0.0\n",
      "90 2020-05-08 0.0\n",
      "91 2020-05-08 0.0\n",
      "92 2020-05-08 0.0\n",
      "93 2020-05-08 0.0\n",
      "94 2020-05-09 0.0\n",
      "95 2020-05-09 0.0\n",
      "96 2020-05-09 0.0\n",
      "97 2020-05-09 0.0\n",
      "98 2020-05-09 0.0\n",
      "99 2020-05-09 0.0\n",
      "100 2020-05-10 0.0\n",
      "101 2020-05-10 -0.06\n",
      "102 2020-05-11 0.0\n",
      "103 2020-05-11 0.0\n",
      "104 2020-05-11 0.0\n",
      "105 2020-05-11 0.0\n",
      "106 2020-05-11 0.0\n",
      "107 2020-05-11 0.11\n",
      "108 2020-05-11 0.0\n",
      "109 2020-05-11 0.0\n",
      "110 2020-05-11 0.0\n",
      "111 2020-05-11 0.0\n",
      "112 2020-05-11 0.0\n",
      "113 2020-05-11 0.0\n",
      "114 2020-05-11 0.0\n",
      "115 2020-05-11 0.0\n",
      "116 2020-05-11 0.0\n",
      "117 2020-05-11 0.0\n",
      "118 2020-05-12 0.0\n",
      "119 2020-05-12 0.0\n",
      "120 2020-05-12 0.0\n",
      "121 2020-05-12 0.0\n",
      "122 2020-05-12 0.0\n",
      "123 2020-05-12 0.0\n",
      "124 2020-05-12 0.0\n",
      "125 2020-05-12 0.0\n",
      "126 2020-05-12 0.0\n",
      "127 2020-05-12 0.0\n",
      "128 2020-05-12 0.0\n",
      "129 2020-05-13 0.0\n",
      "130 2020-05-13 0.0\n",
      "131 2020-05-13 0.14\n",
      "132 2020-05-13 -0.06\n",
      "133 2020-05-13 0.0\n",
      "134 2020-05-13 0.0\n",
      "135 2020-05-13 -0.07\n",
      "136 2020-05-13 0.0\n",
      "137 2020-05-13 0.0\n",
      "138 2020-05-14 0.0\n",
      "139 2020-05-14 0.0\n",
      "140 2020-05-14 0.0\n",
      "141 2020-05-14 0.0\n",
      "142 2020-05-14 0.0\n",
      "143 2020-05-14 0.0\n",
      "144 2020-05-14 0.0\n",
      "145 2020-05-14 0.0\n",
      "146 2020-05-14 0.0\n",
      "147 2020-05-15 0.0\n",
      "148 2020-05-15 0.0\n",
      "149 2020-05-15 0.0\n",
      "150 2020-05-15 0.0\n",
      "151 2020-05-16 0.0\n",
      "152 2020-05-16 0.06\n"
     ]
    }
   ],
   "source": [
    "# Iterate through df_headlines to determine sentiment score for each headline\n",
    "for index, row in df_headlines.iterrows():\n",
    "    headline_tokenized = word_tokenize(row['headline'])\n",
    "    filtered_headline = []\n",
    "    for word in headline_tokenized:\n",
    "        if word not in stop_words:\n",
    "            filtered_headline.append(word)\n",
    "    #print(filtered_headline)\n",
    "    headline_pos = []\n",
    "    headline_neg = []\n",
    "    headline_neu = []\n",
    "    for word in filtered_headline:\n",
    "        if (sid.polarity_scores(word)['compound']) >= 0.5:\n",
    "            headline_pos.append(word)\n",
    "        elif (sid.polarity_scores(word)['compound']) <= -0.5:\n",
    "            headline_neg.append(word)\n",
    "        else:\n",
    "            headline_neu.append(word)\n",
    "    \n",
    "    score = round((1*len(headline_pos) - 1*len(headline_neg) + 0*len(headline_neu))/len(filtered_headline),2)\n",
    "    \n",
    "    \"\"\"if len(headline_neu) >= len(headline_pos) and len(headline_neu) >= len(headline_neg):\n",
    "        score = 0\n",
    "    elif len(headline_pos) > len(headline_neg):\n",
    "        score = 1\n",
    "    else:\n",
    "        score = -1\"\"\"\n",
    "        \n",
    "    \"\"\"if len(headline_pos) > len(headline_neg):\n",
    "        score = 1\n",
    "    elif len(headline_neg) > len(headline_pos):\n",
    "        score = -1\n",
    "    else:\n",
    "        score = 0\"\"\"\n",
    "    #print(len(headline_neu), len(headline_neg), len(headline_pos))\n",
    "    df_headlines.at[index,'score'] = score\n",
    "    print(index, row['date'], score)\n",
    "    #print(len(headline_pos), len(headline_neg), len(headline_neu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>headline</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Jim Cramer advises investors to sell these groups of stocks 'whenever they bounce'</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>Hospitals Made Use of Modified Tesla-Donated Breathing Machines</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-17</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Your boss said 'You're furloughed.' What does that mean exactly?</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>These stocks millennials are investing in are 'very good for speculation ' Jim Cramer says</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Bank of America downgrades Tesla citing too high valuation after stock's recent massive run</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Tesla considers building its next factory in Austin or Tulsa</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>DOJ and state AGs likely to bring antitrust suits against Google: Report</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Final Trades: BABA SLX &amp; PENN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Assessing the stock market after one of the fastest declines and subsequent comebacks in history</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>CNBC</td>\n",
       "      <td>Health officials issue dire warnings; FBI scrutinizes senators' stock sales: This week's recap and best reads</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     source  \\\n",
       "0    2020-04-16  CNBC        \n",
       "1    2020-04-17  Bloomberg   \n",
       "2    2020-04-17  CNBC        \n",
       "3    2020-04-21  CNBC        \n",
       "4    2020-04-22  CNBC        \n",
       "..          ...   ...        \n",
       "148  2020-05-15  CNBC        \n",
       "149  2020-05-15  CNBC        \n",
       "150  2020-05-15  CNBC        \n",
       "151  2020-05-16  CNBC        \n",
       "152  2020-05-16  CNBC        \n",
       "\n",
       "                                                                                                          headline  \\\n",
       "0    Jim Cramer advises investors to sell these groups of stocks 'whenever they bounce'                              \n",
       "1    Hospitals Made Use of Modified Tesla-Donated Breathing Machines                                                 \n",
       "2    Your boss said 'You're furloughed.' What does that mean exactly?                                                \n",
       "3    These stocks millennials are investing in are 'very good for speculation ' Jim Cramer says                      \n",
       "4    Bank of America downgrades Tesla citing too high valuation after stock's recent massive run                     \n",
       "..                                                                                           ...                     \n",
       "148  Tesla considers building its next factory in Austin or Tulsa                                                    \n",
       "149  DOJ and state AGs likely to bring antitrust suits against Google: Report                                        \n",
       "150  Final Trades: BABA SLX & PENN                                                                                   \n",
       "151  Assessing the stock market after one of the fastest declines and subsequent comebacks in history                \n",
       "152  Health officials issue dire warnings; FBI scrutinizes senators' stock sales: This week's recap and best reads   \n",
       "\n",
       "     score  \n",
       "0    0.00   \n",
       "1    0.00   \n",
       "2    0.00   \n",
       "3    0.00   \n",
       "4    0.00   \n",
       "..    ...   \n",
       "148  0.00   \n",
       "149  0.00   \n",
       "150  0.00   \n",
       "151  0.00   \n",
       "152  0.06   \n",
       "\n",
       "[153 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        2020-04-28                                                                               \n",
       "source      CNBC                                                                                     \n",
       "headline    Tesla is poised to beat earnings and possibly qualify for S&P 500 inclusion Barclays says\n",
       "score       0                                                                                        \n",
       "Name: 28, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See score for a particular location to check for accuracy\n",
    "df_headlines.iloc[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of df_headlines to perform grouping operations\n",
    "df_headlines2 = df_headlines.copy()\n",
    "df_headlines2.drop(['source', 'headline'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_group = df_headlines2.groupby('date')\n",
    "#df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for name, group in df_headlines2.groupby('date'):\\n    daily_pos = len(group[group['score'] == 1])\\n    daily_neg = len(group[group['score'] == -1])\\n    daily_neu = len(group[group['score'] == 0])\\n    print(name, daily_pos, daily_neg, daily_neu)\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find daily score for scores of 1, -1, 0; not for continuous variable\n",
    "# https://stackoverflow.com/questions/61806725/iterate-over-a-pandas-data-frame-or-groupby-object?noredirect=1#comment109323032_61806725\n",
    "\"\"\"for name, group in df_headlines2.groupby('date'):\n",
    "    daily_pos = len(group[group['score'] == 1])\n",
    "    daily_neg = len(group[group['score'] == -1])\n",
    "    daily_neu = len(group[group['score'] == 0])\n",
    "    print(name, daily_pos, daily_neg, daily_neu)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daily_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-16</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-17</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-21</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-22</th>\n",
       "      <td>-0.028333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-24</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-26</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-27</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>-0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>-0.014545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>-0.013750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-02</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-04</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-05</th>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-06</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-07</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-08</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-09</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-10</th>\n",
       "      <td>-0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-11</th>\n",
       "      <td>0.006875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-13</th>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-14</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-16</th>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            daily_score\n",
       "date                   \n",
       "2020-04-16  0.000000   \n",
       "2020-04-17  0.000000   \n",
       "2020-04-21  0.000000   \n",
       "2020-04-22 -0.028333   \n",
       "2020-04-23  0.000000   \n",
       "2020-04-24  0.000000   \n",
       "2020-04-25  0.000000   \n",
       "2020-04-26  0.000000   \n",
       "2020-04-27  0.000000   \n",
       "2020-04-28  0.000000   \n",
       "2020-04-29 -0.001000   \n",
       "2020-04-30 -0.014545   \n",
       "2020-05-01 -0.013750   \n",
       "2020-05-02  0.000000   \n",
       "2020-05-04  0.000000   \n",
       "2020-05-05  0.026667   \n",
       "2020-05-06  0.000000   \n",
       "2020-05-07  0.000000   \n",
       "2020-05-08  0.000000   \n",
       "2020-05-09  0.000000   \n",
       "2020-05-10 -0.030000   \n",
       "2020-05-11  0.006875   \n",
       "2020-05-12  0.000000   \n",
       "2020-05-13  0.001111   \n",
       "2020-05-14  0.000000   \n",
       "2020-05-15  0.000000   \n",
       "2020-05-16  0.030000   "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group headlines by date and calculate average score\n",
    "df_group = df_headlines2.groupby('date').mean()\n",
    "df_group.rename(columns = {'score': 'daily_score'}, inplace = True)\n",
    "df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.to_csv('sentiment_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "daily_score    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['daily_score'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
