{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.10:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as pd\n",
    "# import pyspark.sql.SQLContext\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yfinance.Ticker object <TSLA>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla = yf.Ticker(\"TSLA\")\n",
    "tsla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zip': '94304',\n",
       " 'sector': 'Consumer Cyclical',\n",
       " 'fullTimeEmployees': 48016,\n",
       " 'longBusinessSummary': 'Tesla, Inc. designs, develops, manufactures, leases, and sells electric vehicles, and energy generation and storage systems in the United States, China, Netherlands, Norway, and internationally. The company operates in two segments, Automotive; and Energy Generation and Storage. The Automotive segment offers sedans and sport utility vehicles. It also provides electric powertrain components and systems; and services for electric vehicles through its company-owned service locations, and Tesla mobile service technicians, as well as sells used vehicles. This segment markets and sells its products through a network of company-owned stores and galleries, as well as through its own Website. The Energy Generation and Storage segment offers energy storage products, such as rechargeable lithium-ion battery systems for use in homes, industrial, commercial facilities, and utility grids; and designs, manufactures, installs, maintains, leases, and sells solar energy generation and energy storage products to residential and commercial customers. It also provides vehicle insurance services, as well as renewable energy. The company was formerly known as Tesla Motors, Inc. and changed its name to Tesla, Inc. in February 2017. Tesla, Inc. was founded in 2003 and is headquartered in Palo Alto, California.',\n",
       " 'city': 'Palo Alto',\n",
       " 'phone': '650-681-5000',\n",
       " 'state': 'CA',\n",
       " 'country': 'United States',\n",
       " 'companyOfficers': [],\n",
       " 'website': 'http://www.tesla.com',\n",
       " 'maxAge': 1,\n",
       " 'address1': '3500 Deer Creek Road',\n",
       " 'industry': 'Auto Manufacturers',\n",
       " 'previousClose': 819.42,\n",
       " 'regularMarketOpen': 790.51,\n",
       " 'twoHundredDayAverage': 541.9202,\n",
       " 'trailingAnnualDividendYield': None,\n",
       " 'payoutRatio': 0,\n",
       " 'volume24Hr': None,\n",
       " 'regularMarketDayHigh': 824,\n",
       " 'navPrice': None,\n",
       " 'averageDailyVolume10Day': 17923600,\n",
       " 'totalAssets': None,\n",
       " 'regularMarketPreviousClose': 819.42,\n",
       " 'fiftyDayAverage': 649.8682,\n",
       " 'trailingAnnualDividendRate': None,\n",
       " 'open': 790.51,\n",
       " 'toCurrency': None,\n",
       " 'averageVolume10days': 17923600,\n",
       " 'expireDate': None,\n",
       " 'yield': None,\n",
       " 'algorithm': None,\n",
       " 'dividendRate': None,\n",
       " 'exDividendDate': None,\n",
       " 'beta': 1.156884,\n",
       " 'circulatingSupply': None,\n",
       " 'startDate': None,\n",
       " 'regularMarketDayLow': 785,\n",
       " 'priceHint': 2,\n",
       " 'currency': 'USD',\n",
       " 'regularMarketVolume': 16519601,\n",
       " 'lastMarket': None,\n",
       " 'maxSupply': None,\n",
       " 'openInterest': None,\n",
       " 'marketCap': 150389637120,\n",
       " 'volumeAllCurrencies': None,\n",
       " 'strikePrice': None,\n",
       " 'averageVolume': 18466225,\n",
       " 'priceToSalesTrailing12Months': 5.7793264,\n",
       " 'dayLow': 785,\n",
       " 'ask': 0,\n",
       " 'ytdReturn': None,\n",
       " 'askSize': 1100,\n",
       " 'volume': 16519601,\n",
       " 'fiftyTwoWeekHigh': 968.99,\n",
       " 'forwardPE': 69.28181,\n",
       " 'fromCurrency': None,\n",
       " 'fiveYearAvgDividendYield': None,\n",
       " 'fiftyTwoWeekLow': 176.99,\n",
       " 'bid': 0,\n",
       " 'tradeable': False,\n",
       " 'dividendYield': None,\n",
       " 'bidSize': 1300,\n",
       " 'dayHigh': 824,\n",
       " 'exchange': 'NMS',\n",
       " 'shortName': 'Tesla, Inc.',\n",
       " 'longName': 'Tesla, Inc.',\n",
       " 'exchangeTimezoneName': 'America/New_York',\n",
       " 'exchangeTimezoneShortName': 'EDT',\n",
       " 'isEsgPopulated': False,\n",
       " 'gmtOffSetMilliseconds': '-14400000',\n",
       " 'quoteType': 'EQUITY',\n",
       " 'symbol': 'TSLA',\n",
       " 'messageBoardId': 'finmb_27444752',\n",
       " 'market': 'us_market',\n",
       " 'annualHoldingsTurnover': None,\n",
       " 'enterpriseToRevenue': 6.168,\n",
       " 'beta3Year': None,\n",
       " 'profitMargins': -0.0055299997000000005,\n",
       " 'enterpriseToEbitda': 52.923,\n",
       " '52WeekChange': 2.6096208,\n",
       " 'morningStarRiskRating': None,\n",
       " 'forwardEps': 11.71,\n",
       " 'revenueQuarterlyGrowth': None,\n",
       " 'sharesOutstanding': 185371008,\n",
       " 'fundInceptionDate': None,\n",
       " 'annualReportExpenseRatio': None,\n",
       " 'bookValue': 49.584,\n",
       " 'sharesShort': 20097889,\n",
       " 'sharesPercentSharesOut': 0.1086,\n",
       " 'fundFamily': None,\n",
       " 'lastFiscalYearEnd': 1577750400,\n",
       " 'heldPercentInstitutions': 0.5792700000000001,\n",
       " 'netIncomeToCommon': -136000000,\n",
       " 'trailingEps': -0.811,\n",
       " 'lastDividendValue': None,\n",
       " 'SandP52WeekChange': 0.041940093000000005,\n",
       " 'priceToBook': 16.36193,\n",
       " 'heldPercentInsiders': 0.2051,\n",
       " 'nextFiscalYearEnd': 1640908800,\n",
       " 'mostRecentQuarter': 1585612800,\n",
       " 'shortRatio': 1,\n",
       " 'sharesShortPreviousMonthDate': 1584057600,\n",
       " 'floatShares': 147672183,\n",
       " 'enterpriseValue': 160515784704,\n",
       " 'threeYearAverageReturn': None,\n",
       " 'lastSplitDate': None,\n",
       " 'lastSplitFactor': None,\n",
       " 'legalType': None,\n",
       " 'morningStarOverallRating': None,\n",
       " 'earningsQuarterlyGrowth': None,\n",
       " 'dateShortInterest': 1586908800,\n",
       " 'pegRatio': 0.66,\n",
       " 'lastCapGain': None,\n",
       " 'shortPercentOfFloat': 0.1363,\n",
       " 'sharesShortPriorMonth': 16158160,\n",
       " 'category': None,\n",
       " 'fiveYearAverageReturn': None,\n",
       " 'regularMarketPrice': 790.51,\n",
       " 'logo_url': 'https://logo.clearbit.com/tesla.com'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apple = spark.createDataFrame(aapl)\n",
    "tsla.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-22</th>\n",
       "      <td>703.98</td>\n",
       "      <td>734.00</td>\n",
       "      <td>688.71</td>\n",
       "      <td>732.11</td>\n",
       "      <td>14224800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-23</th>\n",
       "      <td>727.60</td>\n",
       "      <td>734.00</td>\n",
       "      <td>703.13</td>\n",
       "      <td>705.63</td>\n",
       "      <td>13236700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-24</th>\n",
       "      <td>710.81</td>\n",
       "      <td>730.73</td>\n",
       "      <td>698.18</td>\n",
       "      <td>725.15</td>\n",
       "      <td>13237600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-27</th>\n",
       "      <td>737.61</td>\n",
       "      <td>799.49</td>\n",
       "      <td>735.00</td>\n",
       "      <td>798.75</td>\n",
       "      <td>20681400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-28</th>\n",
       "      <td>795.64</td>\n",
       "      <td>805.00</td>\n",
       "      <td>756.69</td>\n",
       "      <td>769.12</td>\n",
       "      <td>15222000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-29</th>\n",
       "      <td>790.17</td>\n",
       "      <td>803.20</td>\n",
       "      <td>783.16</td>\n",
       "      <td>800.51</td>\n",
       "      <td>16216000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-30</th>\n",
       "      <td>855.19</td>\n",
       "      <td>869.82</td>\n",
       "      <td>763.50</td>\n",
       "      <td>781.88</td>\n",
       "      <td>28471900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>755.00</td>\n",
       "      <td>772.77</td>\n",
       "      <td>683.04</td>\n",
       "      <td>701.32</td>\n",
       "      <td>32531800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-04</th>\n",
       "      <td>701.00</td>\n",
       "      <td>762.00</td>\n",
       "      <td>698.00</td>\n",
       "      <td>761.19</td>\n",
       "      <td>19237100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-05</th>\n",
       "      <td>789.79</td>\n",
       "      <td>798.92</td>\n",
       "      <td>762.18</td>\n",
       "      <td>768.21</td>\n",
       "      <td>16991700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-06</th>\n",
       "      <td>776.50</td>\n",
       "      <td>789.80</td>\n",
       "      <td>761.11</td>\n",
       "      <td>782.58</td>\n",
       "      <td>11123200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-07</th>\n",
       "      <td>777.21</td>\n",
       "      <td>796.40</td>\n",
       "      <td>772.35</td>\n",
       "      <td>780.04</td>\n",
       "      <td>11527700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-08</th>\n",
       "      <td>793.77</td>\n",
       "      <td>824.00</td>\n",
       "      <td>787.01</td>\n",
       "      <td>819.42</td>\n",
       "      <td>16130100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-11</th>\n",
       "      <td>790.51</td>\n",
       "      <td>824.00</td>\n",
       "      <td>785.00</td>\n",
       "      <td>811.29</td>\n",
       "      <td>16471100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close    Volume  Dividends  Stock Splits\n",
       "Date                                                                         \n",
       "2020-04-22  703.98  734.00  688.71  732.11  14224800          0             0\n",
       "2020-04-23  727.60  734.00  703.13  705.63  13236700          0             0\n",
       "2020-04-24  710.81  730.73  698.18  725.15  13237600          0             0\n",
       "2020-04-27  737.61  799.49  735.00  798.75  20681400          0             0\n",
       "2020-04-28  795.64  805.00  756.69  769.12  15222000          0             0\n",
       "2020-04-29  790.17  803.20  783.16  800.51  16216000          0             0\n",
       "2020-04-30  855.19  869.82  763.50  781.88  28471900          0             0\n",
       "2020-05-01  755.00  772.77  683.04  701.32  32531800          0             0\n",
       "2020-05-04  701.00  762.00  698.00  761.19  19237100          0             0\n",
       "2020-05-05  789.79  798.92  762.18  768.21  16991700          0             0\n",
       "2020-05-06  776.50  789.80  761.11  782.58  11123200          0             0\n",
       "2020-05-07  777.21  796.40  772.35  780.04  11527700          0             0\n",
       "2020-05-08  793.77  824.00  787.01  819.42  16130100          0             0\n",
       "2020-05-11  790.51  824.00  785.00  811.29  16471100          0             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = tsla.history(period=\"14d\")\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rich/dev/spark/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/session.py:714: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.enabled' is set to true; however, failed by the reason below:\n",
      "  PyArrow >= 0.8.0 must be installed; however, it was not found.\n",
      "Attempting non-optimization as 'spark.sql.execution.arrow.fallback.enabled' is set to true.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "tesla = spark.createDataFrame(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Open: string, High: string, Low: string, Close: string, Volume: string, Dividends: string, Stock Splits: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tesla.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying to show the ability to use spark sql below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date: timestamp, Open: double, High: double, Low: double, Close: double, Volume: bigint, Dividends: bigint, Stock Splits: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkdf = sqlContext.createDataFrame(hist.reset_index(drop=False))\n",
    "sparkdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cell below is for potential NLP looping through a dframe.  To be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'itertuples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-07a673713930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclosings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msparkdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclosing\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosing\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mclosing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/spark/spark-2.4.5-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1304\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1305\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'itertuples'"
     ]
    }
   ],
   "source": [
    "closings = []\n",
    "for row in sparkdf.itertuples():\n",
    "    for closing in row[2].split('.'):\n",
    "        if closing != '':\n",
    "            closing.append((row[1], closing))\n",
    "new_df = pandas.sparkdf(closings, columns=['DATE', 'CLOSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+------+------+--------+---------+------------+\n",
      "|               Date|  Open|  High|   Low| Close|  Volume|Dividends|Stock Splits|\n",
      "+-------------------+------+------+------+------+--------+---------+------------+\n",
      "|2020-04-22 00:00:00|703.98| 734.0|688.71|732.11|14224800|        0|           0|\n",
      "|2020-04-23 00:00:00| 727.6| 734.0|703.13|705.63|13236700|        0|           0|\n",
      "|2020-04-24 00:00:00|710.81|730.73|698.18|725.15|13237600|        0|           0|\n",
      "|2020-04-27 00:00:00|737.61|799.49| 735.0|798.75|20681400|        0|           0|\n",
      "|2020-04-28 00:00:00|795.64| 805.0|756.69|769.12|15222000|        0|           0|\n",
      "|2020-04-29 00:00:00|790.17| 803.2|783.16|800.51|16216000|        0|           0|\n",
      "|2020-04-30 00:00:00|855.19|869.82| 763.5|781.88|28471900|        0|           0|\n",
      "|2020-05-01 00:00:00| 755.0|772.77|683.04|701.32|32531800|        0|           0|\n",
      "|2020-05-04 00:00:00| 701.0| 762.0| 698.0|761.19|19237100|        0|           0|\n",
      "|2020-05-05 00:00:00|789.79|798.92|762.18|768.21|16991700|        0|           0|\n",
      "|2020-05-06 00:00:00| 776.5| 789.8|761.11|782.58|11123200|        0|           0|\n",
      "|2020-05-07 00:00:00|777.21| 796.4|772.35|780.04|11527700|        0|           0|\n",
      "|2020-05-08 00:00:00|793.77| 824.0|787.01|819.42|16130100|        0|           0|\n",
      "|2020-05-11 00:00:00|790.51| 824.0| 785.0|811.29|16471100|        0|           0|\n",
      "+-------------------+------+------+------+------+--------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: long (nullable = true)\n",
      " |-- Dividends: long (nullable = true)\n",
      " |-- Stock Splits: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+------+------+------+--------+---------+------------+\n",
      "|               Date|  Open|  High|   Low| Close|  Volume|Dividends|Stock Splits|\n",
      "+-------------------+------+------+------+------+--------+---------+------------+\n",
      "|2020-04-22 00:00:00|703.98| 734.0|688.71|732.11|14224800|        0|           0|\n",
      "|2020-04-23 00:00:00| 727.6| 734.0|703.13|705.63|13236700|        0|           0|\n",
      "|2020-04-24 00:00:00|710.81|730.73|698.18|725.15|13237600|        0|           0|\n",
      "|2020-04-27 00:00:00|737.61|799.49| 735.0|798.75|20681400|        0|           0|\n",
      "|2020-04-28 00:00:00|795.64| 805.0|756.69|769.12|15222000|        0|           0|\n",
      "+-------------------+------+------+------+------+--------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkdf.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sparkdf.createOrReplaceTempView(\"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'desc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-45df5c2d07ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Date\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msparkdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparkdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Close_prev\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'desc'"
     ]
    }
   ],
   "source": [
    "window = Window.partitionBy().orderBy((\"Date\").desc)\n",
    "sparkdf = sparkdf.withColumn(\"Close_prev\", F.lag(df.value).over(my_window))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|    col_name|\n",
      "+------------+\n",
      "|        Date|\n",
      "|        Open|\n",
      "|        High|\n",
      "|         Low|\n",
      "|       Close|\n",
      "|      Volume|\n",
      "|   Dividends|\n",
      "|Stock Splits|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "show = \"\"\"SHOW COLUMNS FROM hist\"\"\"\n",
    "spark.sql(show).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-34de1b47be1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdrop_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Dividends'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Stock Splits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdrop_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# import org.apache.spark.sql.expressions._\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT *, \n",
    "LEAD(Close, 1) OVER (ORDER BY Close) as Close_prev \n",
    "FROM hist\n",
    "\"\"\"\n",
    "# sparkdf = sparkdf.withColumn(\"Close_prev\", F.lag(sparkdf.Close))\n",
    "# sparkdf = sparkdf.withColumn(\"Close_diff\", F.when(F.isnull(sparkdf.Close - sparkdf.Close_prev), 0)\n",
    "#                    .otherwise(sparkdf.Close - sparkdf.Close_prev))\n",
    "\n",
    "drop_list = ['Dividends', 'Stock Splits']\n",
    "query.select([column for column in query.columns if column not in drop_list])\n",
    "spark.sql(query).show()\n",
    "# import org.apache.spark.sql.expressions._\n",
    "# windowSpec = Window.partitionBy(\"Column1\").orderBy(\"Date_Converted\")\n",
    "# import org.apache.spark.sql.functions._\n",
    "# df.withColumn(\"diff_Amt_With_Prev_Month\", $\"Amount\" - when((lag(\"Amount\", 1).over(windowSpec)).isNull, 0).otherwise(lag(\"Amount\", 1).over(windowSpec)))\n",
    "#    .show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e388262fa8b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdrop_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Dividends'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Stock Splits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdrop_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "drop_list = ['Dividends', 'Stock Splits']\n",
    "query.select([column for column in query.columns if column not in drop_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define MYSQL conneciton properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrameWriter' object has no attribute 'jbdc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0e7f055a5ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sparkdf.write.jbdc(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'jdbc:mysql://localhost:3306/stocks'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mystock'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'append'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'root'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'password'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'yourpassword'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'driver'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'com.mysql.cj.jdbc.Driver'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrameWriter' object has no attribute 'jbdc'"
     ]
    }
   ],
   "source": [
    "sparkdf.write.jbdc(\n",
    "    url='jdbc:mysql://localhost:3306/stocks',\n",
    "    table='mystock',\n",
    "    mode='append',\n",
    "    properties={'user':'root','password':'yourpassword','driver':'com.mysql.cj.jdbc.Driver'}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
